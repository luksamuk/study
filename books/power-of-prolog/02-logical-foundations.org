)#+title: The Power of Prolog: Logical Foundations
#+author: Lucas S. Vieira
#+property: header-args:prolog :exports both :noweb strip-export :cache yes :results output
#+startup: showall latexpreview

See [[https://www.logicmatters.net/latex-for-logicians/nd/][LaTeX for Logicians]].

* Logic

[[https://www.youtube.com/watch?v=nlTZQ0FF2Eo][Video]].

Logic is a very broad topic.

Logic  is concerned  with  the properties  of,  and relations  between...

- Syntax (formulae, sentences...)
- Semantics (truth, validity, semantic consequences...)
- Inferences (proofs, theorems, soundness, completeness...)


** Example 1.

Statement *A*: /"It is an apple"/.
Statement *B*: /"It is a banana."/

\begin{equation*}
\frac{\,A \lor B \qquad \lnot A\,}{B}
\end{equation*}

Notation:

\begin{equation*}
\frac{\,\textrm{premises}\,}{\,\textrm{conclusion}\,}
\end{equation*}

The reasoning doesn't  depend on the content  of *A* and *B*.  Not even on
the /truth/ of  those premises. Deduction is done from  the /structure/ of
the statements.

Name of the rule: /disjunctive syllogism/ or /modus tollendo ponens/.

Sequent notation: $A \lor B,\, \lnot A \vdash B$

** Example 2.

"This dog is a pug, and the dog is yours."
   $\vDash$ "This is /your/ pug"

"This dog is a Labrador, and the dog is yours."
   $\vDash$ "This is /your/ labrador".

Suggested /inference/ rule:

"This dog is a *C*, and the dog is yours."
  $\vdash$ "This is your *C*."

By  performing  an   /inductive  inference/,  we  came  up   with  a  /deductive
rule/. However...

"This dog is a father, and the dog is yours."
   $\vdash$ "This is /your/ father."

...the inference  is /unsound/; there  are cases where  it holds, but  there are
also cases where it does not hold, just as described on the last example.

Depending on what we can express, which sentences are true, which deductions are
sound  and  what can  be  proved,  and  depending  on syntactic  formalisms  and
semantics used, we arrive at different logics.

** Logics

- Propositional logic (zero-order logic)
  + Can express NP-complete problems (for every instance of a problem in NP, one
    can construct,  even in polynomial  space, a formula in  propositional logic
    that is satisfiable, iff the instance is a yes-instance.
  +  Therefore, satisfiability  of  propositional  formulae is  as  hard as  the
    hardest problems in NP.
  + Propositional satisfiability was the first problem proved to be NP-complete. 
- Predicate logic
  A family of logics, cathegorized by their orders:
  - First-order predicate logic
    +   Includes   propositional   logic   as   a   sub-formalism,   being   its
      generalization.
    + Maybe the most important type of logic.
    + First-order predicate logic can describe a Turing machine.
    +  Therefore results  of  a  computation are  semantic  consequences of  the
      description.
  - Second and higher-order logic
    Example: $\left(\forall P\right)\left(P(0)  \land \left(\forall k\right)\left(P(k) \rightarrow  P(k + 1)\right)
    \rightarrow \left(\forall n\right)\left(P(n)\right)\right)$
    + Quantification  over relations between domain  elements, complementing the
      relations over individuals  of first-order logic. For  higher order logic,
      we quantify over relations between relations, and so on.

General principle: *Increased expressiveness has a price.*

** Classical Logic

Another way to  characterize logic is by making a  distinction between classical
and non-classical logics.

"Classical logic" denotes propositional and  predicate logic as found in Frege's
/Begriffsschift/ (1879).

Characteristic properties:

+ Law of excluded middle ($A \lor \lnot A$ -- /tertium non datur/);
+ Commutativity of conjunction ($\left(A \land B\right) \rightarrow \left(B \land A\right)$);
+ Law of non-contradiction ($\lnot (A \land \lnot A)$);
+ etc

Some situations justify different foundational  laws. For example when reasoning
about  proofs, $\nvDash  (A \lor  \lnot  A)$, since  we  have no  proof of  some
conjecture, but we also have no proof for the negation of the same conjecture.

** Non-classical Logics

Different foundational laws lead to different logics.

Examples:

+ Intuitionistic logic (the law of excluded middle does not hold);
+ Modal logics (temporal logic, epistemic logic, etc);
+ Many-valued logics (≈Åukasiewicz logic, fuzzy  logic, etc -- True and False are
  not the only possible truth-values);
+  Substructural  logics  (linear  logic,  relevance logic,  etc  --  Relate  to
  structural rules of logic such as contraction or extension);
+ Etc.

Similar  to programming  languages: Pick  a logic  that is  /suitable/ for  your
domains of interest.

One could compare the relation "logic $\leftrightarrow$ computer science" to the
relation "mathematics $\leftrightarrow$ physics". (Symbols here used lightly!)

** Prolog

Prolog  is  a *programming  language*,  based  on  a Turing-complete  subset  of
predicate logic. It also supports a few higher-order and meta-logical features.

Its execution mechanism can be regarded as a specific form of /theorem proving/,
being /incomplete/ in  the sense that, in general, not  all logical consequences
of a program are derived (for example, think of side effects).

/"Prolog  is an  efficient  programming language  because it  is  a very  stupid
theorem prover."/ -- Richard O'Keefe, /The Craft of Prolog/

However, Prolog is often a very good choice for /implementing/ theorem provers.

* Predicate Logic

(This is kind of an obvious bit for me,  so I'm going to skip this and make some
remarks to level the naming conventions).

A *model* is an interpretation for a formula.

For   a   formula    $\mathcal{F}$,   if   $(\exists\mathcal{M})(\mathcal{M}   =
\textrm{true})$, then the formula is *satisfiable*.

A formula is *valid* if $(\forall \mathcal{M})(\mathcal{M} = \textrm{true})$.

Semantic consequence: If every  model where A is true also makes  B true, then B
is a *semantic consequence* of A.

$\left((\forall \mathcal{M} \| A = true) \rightarrow (B = true)\right) \implies (A \vDash B)$.

** Relations

+ $<(x, y) \equiv x < y$;
+ $P(x, y) \equiv xPy$;
+ $a = b \equiv =(a, b)$
+ $Sum(x, y, z)$: The predicate is true iff $z$ is the sum of $x$ and $y$.
+ Etc.

** Theories

A *theory* is a set of sentences (we use the word liberally here). The sentences
are called *theorems*, commonly specified as a set of *nonlogical axioms*.

Example. Zermelo-Fraenkel set theory (ZF):

+ Axiom of extensionality.
  $(\forall  x)(\forall y)\left((\forall  z)(z \in  x \leftrightarrow  z \in  y)
  \rightarrow x = y \right)$
+ Axiom of regularity. (somewhat prevents recursion on families of sets)
  $(\forall  x)\left(x \neq  \emptyset  \rightarrow (\exists  y)\left((y \in  x)
  \land (y \cap x = \emptyset)\right)\right)$
+ Axiom of subset.
  $(z \subseteq x) \leftrightarrow (\forall q)\left((q \in z) \rightarrow (q \in
  x)\right)$
+ Axiom of powersets.
  $(\forall  x)(\exists y)(\forall  z)\left((z \subseteq  x) \rightarrow  (z \in
  y)\right)$
+ Etc., and the semantic consequences of these axioms (since this is a deductive
  theory).

Questions of relevance:
- *(Semantic) Consistency*  aka *Satisfiability*. Does the  conjunction of these
  sentences have a model?
- *(Syntactic)         Consistency*.          $\phi\notin\textrm{ZF}$         or
  $\lnot\phi\notin\textrm{ZF}$ for all sentences $\phi$?

Many important  statements are /independent/ of  ZF: $\phi\notin\textrm{ZF}$ and
$\lnot\phi\notin\textrm{ZF}$.

What are the semantic consequences of these axioms?

How do we even determine semantic consequences?

*There are infinitely  many possible interpretations!* Also, *a  theory may have
infinitely  many axioms!*  (e.g.   ZF  has axiom  schemas,  and  is not  finally
axiomatizable).

** Model existence theorem

If  a  first-order  theory  with  a  well-orderable  language  is  syntactically
consistent, then  it has a model  (The semantic notion of  consistency coincides
with its syntactic notion).

This theorem is an  important link between syntax and semantics,  and ZF and ZFC
are examples of such theories.

This connection  generally breaks down  for higher order logics,  which normally
are syntactically consistent, but have no model.

** Deductive systems

*Main goal:* Prove semantic consequences on a purely syntactic basis.

A *proof*  is a finite  sequence of inferences, starting  from a set  of logical
axioms and using inference rules to deduce theorems.

A formula A  is a syntactic consequence  of a set of formulas  $\Gamma$ (this is
written as $\Gamma \vdash A$) if there is a proof of A from $\Gamma$.

There are many deductive systems for predicate logic:

+ *Hilbert-style systems.*
  Good for comparing different logics, but  not so good for automated reasoning;
  generally have many axioms and a small number of inference rules.
+ *Gentzen-style systems.*
  Generally have more inference rules than Hilbert-style systems.
  - *Natural deduction.*
    Attempts  to emulate  the kind  of reasoning  that one  could call  "natural
    reasoning".    Closely  relates   to   $\lambda\textrm{-calculus}$  by   the
    Curry-Howard Isomorphism.
  - *Sequent calculus.*
+ *Resolution.*
  Optimal for automated  reasoning. Prolog uses specific forms  of resolution to
  derive semantic consequences from programs.
+ Etc.

*** Most important properties of deductive systems

**** Soundness

$\Gamma \vdash A \Rightarrow \Gamma \vDash A$

If we derive  a syntactic consequence from  the formulas of the  system, then it
must also be  a semantic consequence of  these formulas. If it is  not the case,
the system is *unsound*.

**** Completeness

$\Gamma \vDash A \Rightarrow \Gamma \vdash A$

If we can  derive all semantic consequences  of the formulas of the  system in a
syntactic manner, then the  system is a complete system. This  way, we can focus
on purely syntactic reasoning, so we don't need to consider all interpretations.

*** Deduction theorem

$\Gamma, A \vdash B \Rightarrow \Gamma \vdash A \rightarrow B$

If we can prove something (A) under  a specific assumption (B), then we can also
prove that A implies B.

This  gives the  formal justification  for  conditional proofs,  since we  could
then consider the particular case starting from an assumption (A):

$A \vdash B \Rightarrow\,\,\, \vdash A \rightarrow B$

** Notable properties of first-order predicate logic

+ *Monotonicity of entailment*: $P \vDash C \implies P, A \vDash C$
+ *(Semantic) Completeness*, by G√∂del's, /completeness theorem/:
  - For  every first-order  theory T  with  a well-orderable  language, and  any
    sentence s in the language of T: $T \vDash s \iff T \vdash s$.
  - In  particular ($T = \emptyset$),  also weak  completeness: $\vDash  s \iff
    \vdash s$.
    + $\iff$ Every sentence is ether satisfiable or refutable.
+ *Compactness*: A set $S$ of first-ordered sentences has a model if and only if
  every finite subset of $S$ has a model. This is equivalent to the completeness
  theorem.
+ Upward  and downward  *L√∂wenheim-Skolem theorem*:  If a  countable first-order
  theory has an infinite model, then for every infinite cardinal number $\kappa$
  it has model of size $\kappa$.
+  *Lindstr√∂m's   theorem*:  First-order  predicate   logic  is,  in   a  sense,
  characterized  by the  compactness theorem  and the  downward L√∂wenheim-Skolem
  theorem. Therefore,  to get  a more  expressive logic,  one of  these theorems
  needs to  be sacrificed  (e.g. in  second-order logic,  both theorems  fail to
  hold).
  
*** Syntactic completeness

A formal  system $\mathcal{S}$ is *syntactically  complete* if and only  if, for
each  sentence   $\phi$  of   the  system,  either   $\mathcal{S}\vdash\phi$  or
$\mathcal{S}\vdash\lnot\phi$.

Such an $\mathcal{S}$  is also called deductively  complete, maximally complete,
negation complete, or complete.

Example: ZF, if it is consistent, is complete.

+ *G√∂del's  first incompleteness theorem:*  Any consistent formal  system within
  which a certain amount of arithmetic can be carried out is incomplete.

*** Skolem's paradox

On one hand: ZF $\vdash$ "There is an uncountable set."

On the other hand, ZF, if consistent, has a countable model.

Therefore,  the notion  of countability  is relative:  there are  sets that  are
countable from the  perspective of certain models, but not  from the perspective
of some models.
